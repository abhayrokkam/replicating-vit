{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "super_directory = os.path.abspath('..')\n",
    "sys.path.append(super_directory)\n",
    "\n",
    "from data_setup import get_dataloaders\n",
    "from vit import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters from the paper (except batch size - computational bottleneck)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Patches\n",
    "PATCH_SIZE = (7, 7)\n",
    "NUM_PATCHES = int((28 / 7) ** 2)\n",
    "\n",
    "# Patches to Embeddings\n",
    "EMBED_DIMS = 48\n",
    "\n",
    "# Number of Attention heads\n",
    "NUM_ATTENTION_HEADS = 12\n",
    "\n",
    "# Number of hidden layers in MLP block\n",
    "RATIO_HIDDEN_MLP = 4\n",
    "\n",
    "# Number of encoder blocks\n",
    "NUM_ENC_BLOCKS = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "data_path = Path('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the dataloaders\n",
    "train_dataloader, test_dataloader, class_labels = get_dataloaders(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batched images shape: torch.Size([32, 1, 28, 28]) -> (batch_dim, color_channels, image_height, image_width)\n"
     ]
    }
   ],
   "source": [
    "# Get X and y from the first batch\n",
    "batch_X, batch_y = next(iter(train_dataloader))\n",
    "\n",
    "print(f\"Batched images shape: {batch_X.shape} -> (batch_dim, color_channels, image_height, image_width)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the custom created ViT model\n",
    "model = ViT(in_channels=1,\n",
    "            out_dims=len(class_labels),\n",
    "            patch_size=PATCH_SIZE,\n",
    "            num_patches=NUM_PATCHES,\n",
    "            embed_dims=EMBED_DIMS,\n",
    "            num_attn_heads=NUM_ATTENTION_HEADS,\n",
    "            ratio_hidden_mlp=RATIO_HIDDEN_MLP,\n",
    "            num_encoder_blocks=NUM_ENC_BLOCKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type (var_name))                                 Input Shape     Output Shape    Param #         Trainable\n",
       "===================================================================================================================\n",
       "ViT (ViT)                                               [1, 1, 28, 28]  [1, 10]         --              True\n",
       "├─DataEmbeddings (data_embeddings)                      [1, 1, 28, 28]  [1, 17, 48]     864             True\n",
       "│    └─Conv2d (conv_layer)                              [1, 1, 28, 28]  [1, 48, 4, 4]   2,400           True\n",
       "│    └─Flatten (flatten)                                [1, 48, 4, 4]   [1, 48, 16]     --              --\n",
       "├─Sequential (encoder_blocks)                           [1, 17, 48]     [1, 17, 48]     --              True\n",
       "│    └─EncoderBlock (0)                                 [1, 17, 48]     [1, 17, 48]     --              True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     96              True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --              [1, 17, 48]     9,408           True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     (recursive)     True\n",
       "│    │    └─Sequential (mlp)                            [1, 17, 48]     [1, 17, 48]     18,672          True\n",
       "│    └─EncoderBlock (1)                                 [1, 17, 48]     [1, 17, 48]     --              True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     96              True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --              [1, 17, 48]     9,408           True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     (recursive)     True\n",
       "│    │    └─Sequential (mlp)                            [1, 17, 48]     [1, 17, 48]     18,672          True\n",
       "│    └─EncoderBlock (2)                                 [1, 17, 48]     [1, 17, 48]     --              True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     96              True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --              [1, 17, 48]     9,408           True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     (recursive)     True\n",
       "│    │    └─Sequential (mlp)                            [1, 17, 48]     [1, 17, 48]     18,672          True\n",
       "│    └─EncoderBlock (3)                                 [1, 17, 48]     [1, 17, 48]     --              True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     96              True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --              [1, 17, 48]     9,408           True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     (recursive)     True\n",
       "│    │    └─Sequential (mlp)                            [1, 17, 48]     [1, 17, 48]     18,672          True\n",
       "│    └─EncoderBlock (4)                                 [1, 17, 48]     [1, 17, 48]     --              True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     96              True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --              [1, 17, 48]     9,408           True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     (recursive)     True\n",
       "│    │    └─Sequential (mlp)                            [1, 17, 48]     [1, 17, 48]     18,672          True\n",
       "│    └─EncoderBlock (5)                                 [1, 17, 48]     [1, 17, 48]     --              True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     96              True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --              [1, 17, 48]     9,408           True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     (recursive)     True\n",
       "│    │    └─Sequential (mlp)                            [1, 17, 48]     [1, 17, 48]     18,672          True\n",
       "│    └─EncoderBlock (6)                                 [1, 17, 48]     [1, 17, 48]     --              True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     96              True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --              [1, 17, 48]     9,408           True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     (recursive)     True\n",
       "│    │    └─Sequential (mlp)                            [1, 17, 48]     [1, 17, 48]     18,672          True\n",
       "│    └─EncoderBlock (7)                                 [1, 17, 48]     [1, 17, 48]     --              True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     96              True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --              [1, 17, 48]     9,408           True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     (recursive)     True\n",
       "│    │    └─Sequential (mlp)                            [1, 17, 48]     [1, 17, 48]     18,672          True\n",
       "│    └─EncoderBlock (8)                                 [1, 17, 48]     [1, 17, 48]     --              True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     96              True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --              [1, 17, 48]     9,408           True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     (recursive)     True\n",
       "│    │    └─Sequential (mlp)                            [1, 17, 48]     [1, 17, 48]     18,672          True\n",
       "│    └─EncoderBlock (9)                                 [1, 17, 48]     [1, 17, 48]     --              True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     96              True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --              [1, 17, 48]     9,408           True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     (recursive)     True\n",
       "│    │    └─Sequential (mlp)                            [1, 17, 48]     [1, 17, 48]     18,672          True\n",
       "│    └─EncoderBlock (10)                                [1, 17, 48]     [1, 17, 48]     --              True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     96              True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --              [1, 17, 48]     9,408           True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     (recursive)     True\n",
       "│    │    └─Sequential (mlp)                            [1, 17, 48]     [1, 17, 48]     18,672          True\n",
       "│    └─EncoderBlock (11)                                [1, 17, 48]     [1, 17, 48]     --              True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     96              True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --              [1, 17, 48]     9,408           True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 17, 48]     [1, 17, 48]     (recursive)     True\n",
       "│    │    └─Sequential (mlp)                            [1, 17, 48]     [1, 17, 48]     18,672          True\n",
       "│    └─LayerNorm (12)                                   [1, 17, 48]     [1, 17, 48]     96              True\n",
       "├─Sequential (classifier)                               [1, 48]         [1, 10]         --              True\n",
       "│    └─Linear (0)                                       [1, 48]         [1, 192]        9,408           True\n",
       "│    └─Linear (1)                                       [1, 192]        [1, 10]         1,930           True\n",
       "===================================================================================================================\n",
       "Total params: 352,810\n",
       "Trainable params: 352,810\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.28\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.56\n",
       "Params size (MB): 0.96\n",
       "Estimated Total Size (MB): 1.52\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model summary\n",
    "summary(model,\n",
    "        input_size=(1, 1, 28, 28),                                                # Batch dim, color channels, height, width\n",
    "        col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
    "        col_width=15,\n",
    "        row_settings=['var_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: torch.Size([32, 10]) -> (batch_dim, num_classes)\n"
     ]
    }
   ],
   "source": [
    "# Output of ViT\n",
    "model = model.to(device)\n",
    "batch_X = batch_X.to(device)\n",
    "\n",
    "vit_out = model(batch_X)\n",
    "print(f\"Model output shape: {vit_out.shape} -> (batch_dim, num_classes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0611, 0.0810, 0.0973, 0.1126, 0.0414, 0.1122, 0.1472, 0.1249, 0.1191,\n",
       "         0.1030],\n",
       "        [0.0665, 0.0845, 0.1014, 0.1094, 0.0426, 0.1035, 0.1502, 0.1241, 0.1191,\n",
       "         0.0987],\n",
       "        [0.0657, 0.0869, 0.1065, 0.1038, 0.0449, 0.1034, 0.1560, 0.1210, 0.1162,\n",
       "         0.0955],\n",
       "        [0.0598, 0.0860, 0.0936, 0.1097, 0.0417, 0.1183, 0.1442, 0.1293, 0.1141,\n",
       "         0.1033],\n",
       "        [0.0633, 0.0810, 0.0912, 0.1148, 0.0395, 0.1141, 0.1448, 0.1274, 0.1208,\n",
       "         0.1031],\n",
       "        [0.0638, 0.0835, 0.1001, 0.1099, 0.0415, 0.1059, 0.1531, 0.1217, 0.1215,\n",
       "         0.0990],\n",
       "        [0.0631, 0.0842, 0.1029, 0.1077, 0.0453, 0.1124, 0.1437, 0.1288, 0.1123,\n",
       "         0.0996],\n",
       "        [0.0625, 0.0815, 0.1018, 0.1089, 0.0438, 0.1157, 0.1406, 0.1260, 0.1174,\n",
       "         0.1018],\n",
       "        [0.0630, 0.0831, 0.0998, 0.1124, 0.0419, 0.1068, 0.1478, 0.1248, 0.1190,\n",
       "         0.1013],\n",
       "        [0.0637, 0.0791, 0.0949, 0.1156, 0.0409, 0.1130, 0.1415, 0.1274, 0.1208,\n",
       "         0.1030],\n",
       "        [0.0611, 0.0811, 0.0952, 0.1121, 0.0411, 0.1176, 0.1448, 0.1248, 0.1200,\n",
       "         0.1021],\n",
       "        [0.0660, 0.0862, 0.1037, 0.1084, 0.0434, 0.1017, 0.1525, 0.1240, 0.1165,\n",
       "         0.0976],\n",
       "        [0.0631, 0.0801, 0.0950, 0.1145, 0.0413, 0.1145, 0.1409, 0.1289, 0.1187,\n",
       "         0.1031],\n",
       "        [0.0642, 0.0876, 0.1065, 0.1046, 0.0458, 0.1058, 0.1496, 0.1234, 0.1146,\n",
       "         0.0979],\n",
       "        [0.0655, 0.0883, 0.1031, 0.1060, 0.0446, 0.1067, 0.1456, 0.1257, 0.1168,\n",
       "         0.0978],\n",
       "        [0.0620, 0.0807, 0.0943, 0.1133, 0.0411, 0.1160, 0.1449, 0.1260, 0.1192,\n",
       "         0.1026],\n",
       "        [0.0634, 0.0768, 0.0951, 0.1150, 0.0400, 0.1121, 0.1470, 0.1255, 0.1221,\n",
       "         0.1030],\n",
       "        [0.0633, 0.0811, 0.0929, 0.1147, 0.0399, 0.1135, 0.1452, 0.1272, 0.1198,\n",
       "         0.1024],\n",
       "        [0.0605, 0.0841, 0.0958, 0.1089, 0.0407, 0.1140, 0.1513, 0.1270, 0.1155,\n",
       "         0.1022],\n",
       "        [0.0640, 0.0817, 0.0969, 0.1137, 0.0411, 0.1090, 0.1449, 0.1249, 0.1223,\n",
       "         0.1014],\n",
       "        [0.0630, 0.0809, 0.0991, 0.1122, 0.0415, 0.1077, 0.1493, 0.1250, 0.1194,\n",
       "         0.1019],\n",
       "        [0.0629, 0.0820, 0.0931, 0.1140, 0.0407, 0.1136, 0.1456, 0.1245, 0.1215,\n",
       "         0.1021],\n",
       "        [0.0667, 0.0835, 0.1035, 0.1085, 0.0422, 0.0982, 0.1575, 0.1244, 0.1205,\n",
       "         0.0950],\n",
       "        [0.0628, 0.0821, 0.0987, 0.1122, 0.0429, 0.1113, 0.1427, 0.1279, 0.1178,\n",
       "         0.1015],\n",
       "        [0.0671, 0.0886, 0.1050, 0.1056, 0.0450, 0.1024, 0.1502, 0.1232, 0.1159,\n",
       "         0.0970],\n",
       "        [0.0647, 0.0848, 0.1052, 0.1066, 0.0428, 0.1024, 0.1571, 0.1212, 0.1177,\n",
       "         0.0974],\n",
       "        [0.0646, 0.0789, 0.0987, 0.1124, 0.0406, 0.1065, 0.1527, 0.1240, 0.1217,\n",
       "         0.0999],\n",
       "        [0.0618, 0.0883, 0.0980, 0.1054, 0.0431, 0.1180, 0.1339, 0.1287, 0.1180,\n",
       "         0.1046],\n",
       "        [0.0627, 0.0835, 0.0957, 0.1128, 0.0416, 0.1112, 0.1468, 0.1258, 0.1189,\n",
       "         0.1009],\n",
       "        [0.0649, 0.0893, 0.1000, 0.1074, 0.0431, 0.1095, 0.1401, 0.1268, 0.1186,\n",
       "         0.1004],\n",
       "        [0.0636, 0.0797, 0.0982, 0.1129, 0.0405, 0.1074, 0.1526, 0.1230, 0.1214,\n",
       "         0.1007],\n",
       "        [0.0635, 0.0859, 0.1027, 0.1054, 0.0439, 0.1120, 0.1488, 0.1240, 0.1147,\n",
       "         0.0991]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating probabilities of each class for the first batch\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "prob_out = softmax(vit_out)\n",
    "prob_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted classes from the un-trained model\n",
    "pred_class_idx = torch.argmax(prob_out, dim=1)\n",
    "pred_class_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 3, 6, 8, 5, 2, 8, 5, 6, 5, 7, 4, 7, 4, 2, 5, 5, 5, 9, 6, 6, 5, 4, 9,\n",
       "        2, 4, 6, 1, 5, 3, 2, 9])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual classes idx\n",
    "batch_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".replicating-vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
