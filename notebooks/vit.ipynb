{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "super_directory = os.path.abspath('..')\n",
    "sys.path.append(super_directory)\n",
    "\n",
    "from data_setup import get_dataloaders\n",
    "from vit import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters from the paper (except batch size - computational bottleneck)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Patches\n",
    "PATCH_SIZE = (16, 16)\n",
    "NUM_PATCHES = int((224 / 16) ** 2)\n",
    "\n",
    "# Patches to Embeddings\n",
    "EMBED_DIMS = 768\n",
    "\n",
    "# Number of Attention heads\n",
    "NUM_ATTENTION_HEADS = 4\n",
    "\n",
    "# Number of hidden layers in MLP block\n",
    "RATIO_HIDDEN_MLP = 4\n",
    "\n",
    "# Number of encoder blocks\n",
    "NUM_ENC_BLOCKS = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "data_path = Path('../data/desserts')\n",
    "train_path = data_path / 'train'\n",
    "test_path = data_path / 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the dataloaders\n",
    "train_dataloader, test_dataloader, class_labels = get_dataloaders(train_path=train_path,\n",
    "                                                                  test_path=test_path,\n",
    "                                                                  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batched images shape: torch.Size([32, 3, 224, 224]) -> (batch_dim, color_channels, image_height, image_width)\n"
     ]
    }
   ],
   "source": [
    "# Get X and y from the first batch\n",
    "batch_X, batch_y = next(iter(train_dataloader))\n",
    "\n",
    "print(f\"Batched images shape: {batch_X.shape} -> (batch_dim, color_channels, image_height, image_width)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the custom created ViT model\n",
    "model = ViT(in_channels=3,\n",
    "            out_dims=len(class_labels),\n",
    "            patch_size=PATCH_SIZE,\n",
    "            num_patches=NUM_PATCHES,\n",
    "            embed_dims=EMBED_DIMS,\n",
    "            num_attn_heads=NUM_ATTENTION_HEADS,\n",
    "            ratio_hidden_mlp=RATIO_HIDDEN_MLP,\n",
    "            num_encoder_blocks=NUM_ENC_BLOCKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=======================================================================================================================================\n",
       "Layer (type (var_name))                                 Input Shape          Output Shape         Param #              Trainable\n",
       "=======================================================================================================================================\n",
       "ViT (ViT)                                               [1, 3, 224, 224]     [1, 5]               --                   True\n",
       "├─DataEmbeddings (data_embeddings)                      [1, 3, 224, 224]     [1, 197, 768]        152,064              True\n",
       "│    └─Conv2d (conv_layer)                              [1, 3, 224, 224]     [1, 768, 14, 14]     590,592              True\n",
       "│    └─Flatten (flatten)                                [1, 768, 14, 14]     [1, 768, 196]        --                   --\n",
       "├─Sequential (encoder_blocks)                           [1, 197, 768]        [1, 197, 768]        --                   True\n",
       "│    └─EncoderBlock (0)                                 [1, 197, 768]        [1, 197, 768]        --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [1, 197, 768]        2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [1, 197, 768]        [1, 197, 768]        4,722,432            True\n",
       "│    └─EncoderBlock (1)                                 [1, 197, 768]        [1, 197, 768]        --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [1, 197, 768]        2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [1, 197, 768]        [1, 197, 768]        4,722,432            True\n",
       "│    └─EncoderBlock (2)                                 [1, 197, 768]        [1, 197, 768]        --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [1, 197, 768]        2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [1, 197, 768]        [1, 197, 768]        4,722,432            True\n",
       "│    └─EncoderBlock (3)                                 [1, 197, 768]        [1, 197, 768]        --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [1, 197, 768]        2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [1, 197, 768]        [1, 197, 768]        4,722,432            True\n",
       "│    └─EncoderBlock (4)                                 [1, 197, 768]        [1, 197, 768]        --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [1, 197, 768]        2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [1, 197, 768]        [1, 197, 768]        4,722,432            True\n",
       "│    └─EncoderBlock (5)                                 [1, 197, 768]        [1, 197, 768]        --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [1, 197, 768]        2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [1, 197, 768]        [1, 197, 768]        4,722,432            True\n",
       "│    └─EncoderBlock (6)                                 [1, 197, 768]        [1, 197, 768]        --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [1, 197, 768]        2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [1, 197, 768]        [1, 197, 768]        4,722,432            True\n",
       "│    └─EncoderBlock (7)                                 [1, 197, 768]        [1, 197, 768]        --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [1, 197, 768]        2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [1, 197, 768]        [1, 197, 768]        4,722,432            True\n",
       "│    └─EncoderBlock (8)                                 [1, 197, 768]        [1, 197, 768]        --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [1, 197, 768]        2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [1, 197, 768]        [1, 197, 768]        4,722,432            True\n",
       "│    └─EncoderBlock (9)                                 [1, 197, 768]        [1, 197, 768]        --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [1, 197, 768]        2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [1, 197, 768]        [1, 197, 768]        4,722,432            True\n",
       "│    └─EncoderBlock (10)                                [1, 197, 768]        [1, 197, 768]        --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [1, 197, 768]        2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [1, 197, 768]        [1, 197, 768]        4,722,432            True\n",
       "│    └─EncoderBlock (11)                                [1, 197, 768]        [1, 197, 768]        --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [1, 197, 768]        2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [1, 197, 768]        [1, 197, 768]        (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [1, 197, 768]        [1, 197, 768]        4,722,432            True\n",
       "├─Linear (classifier)                                   [1, 768]             [1, 5]               3,845                True\n",
       "=======================================================================================================================================\n",
       "Total params: 85,782,533\n",
       "Trainable params: 85,782,533\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 172.47\n",
       "=======================================================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 102.88\n",
       "Params size (MB): 229.13\n",
       "Estimated Total Size (MB): 332.61\n",
       "======================================================================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model summary\n",
    "summary(model,\n",
    "        input_size=(1, 3, 224, 224),                                                # Batch dim, color channels, height, width\n",
    "        col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
    "        col_width=20,\n",
    "        row_settings=['var_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: torch.Size([32, 5]) -> (batch_dim, num_classes)\n"
     ]
    }
   ],
   "source": [
    "# Output of ViT\n",
    "model = model.to(device)\n",
    "batch_X = batch_X.to(device)\n",
    "\n",
    "vit_out = model(batch_X)\n",
    "print(f\"Model output shape: {vit_out.shape} -> (batch_dim, num_classes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1518, 0.0820, 0.4683, 0.1372, 0.1607],\n",
       "        [0.1531, 0.0779, 0.4715, 0.1337, 0.1637],\n",
       "        [0.1568, 0.0798, 0.4683, 0.1334, 0.1617],\n",
       "        [0.1559, 0.0843, 0.4532, 0.1444, 0.1622],\n",
       "        [0.1586, 0.0842, 0.4471, 0.1477, 0.1623],\n",
       "        [0.1421, 0.0826, 0.4810, 0.1357, 0.1586],\n",
       "        [0.1529, 0.0863, 0.4492, 0.1514, 0.1601],\n",
       "        [0.1488, 0.0906, 0.4423, 0.1579, 0.1605],\n",
       "        [0.1283, 0.0906, 0.4905, 0.1365, 0.1541],\n",
       "        [0.1470, 0.0805, 0.4788, 0.1332, 0.1606],\n",
       "        [0.1577, 0.0816, 0.4573, 0.1410, 0.1623],\n",
       "        [0.1366, 0.0889, 0.4789, 0.1395, 0.1561],\n",
       "        [0.1473, 0.0866, 0.4650, 0.1430, 0.1582],\n",
       "        [0.1387, 0.0852, 0.4831, 0.1366, 0.1564],\n",
       "        [0.1339, 0.0931, 0.4711, 0.1456, 0.1563],\n",
       "        [0.1430, 0.0861, 0.4633, 0.1488, 0.1587],\n",
       "        [0.1509, 0.0795, 0.4782, 0.1300, 0.1613],\n",
       "        [0.1469, 0.0831, 0.4740, 0.1367, 0.1594],\n",
       "        [0.1653, 0.0798, 0.4536, 0.1363, 0.1649],\n",
       "        [0.1570, 0.0837, 0.4572, 0.1380, 0.1641],\n",
       "        [0.1562, 0.0819, 0.4635, 0.1384, 0.1599],\n",
       "        [0.1434, 0.0900, 0.4447, 0.1658, 0.1561],\n",
       "        [0.1537, 0.0784, 0.4741, 0.1306, 0.1632],\n",
       "        [0.1440, 0.0853, 0.4717, 0.1390, 0.1600],\n",
       "        [0.1642, 0.0809, 0.4558, 0.1356, 0.1635],\n",
       "        [0.1324, 0.0905, 0.4811, 0.1403, 0.1557],\n",
       "        [0.1539, 0.0780, 0.4754, 0.1304, 0.1623],\n",
       "        [0.1183, 0.1045, 0.4803, 0.1434, 0.1536],\n",
       "        [0.1474, 0.0858, 0.4604, 0.1444, 0.1619],\n",
       "        [0.1416, 0.0878, 0.4697, 0.1425, 0.1584],\n",
       "        [0.1462, 0.0857, 0.4649, 0.1441, 0.1591],\n",
       "        [0.1423, 0.0863, 0.4705, 0.1420, 0.1590]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating probabilities of each class for the first batch\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "prob_out = softmax(vit_out)\n",
    "prob_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted classes from the un-trained model\n",
    "pred_class_idx = torch.argmax(prob_out, dim=1)\n",
    "pred_class_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 3, 0, 4, 0, 4, 4, 0, 2, 0, 1, 1, 1, 3, 1, 2, 1, 3, 3, 4, 0, 4, 1,\n",
       "        2, 0, 1, 0, 4, 4, 1, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual classes idx\n",
    "batch_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".replicating-vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
